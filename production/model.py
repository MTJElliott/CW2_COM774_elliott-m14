# -*- coding: utf-8 -*-
"""OULA_Decision_Tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XpKx_mAVf5QfnnotBy3TfiBz8HMtcgJr
"""

#This python script ( initially Jupyter Notebook) was created by Marc Elliott to test a decision tree for predicting student performance on the OULA dataset
#The dataset has been preprocessed in another python file already
#Two experiments are being ran - one using the full feature set, the other using the most important (based on Boruta score of 20+)

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import numpy as np
import pandas as pd
import random
import argparse
import joblib #For saving the model
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
import mlflow
import mlflow.sklearn

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier


from sklearn.metrics import accuracy_score, precision_score, recall_score


# Get the arugments we need to avoid fixing the dataset path in code
parser = argparse.ArgumentParser()
parser.add_argument("--trainingdata", type=str, required=True, help='Dataset for training')
parser.add_argument("--testingdata", type=str, required=True, help='Dataset for testing')
args = parser.parse_args()

#Load preprocessed training and test data
train = pd.read_csv(args.trainingdata)
test = pd.read_csv(args.testingdata)

#Prepare training data

#Drop target feature from training dataset
X_train = train.drop(columns=['final_result'])

#Get target feature (y) for training dataset
y_train = train['final_result']

#Prepare test data
#Drop target feature from test dataset
X_test = test.drop(columns=['final_result'])

#Get target feature (y) for test dataset
y_test = test['final_result']

mlflow.autolog(log_input_examples=True)

def evaluate_and_log(model_name, model, X_train, y_train, X_test, y_test):
    """
    Trains model, evaluates it, and logs metrics + model to MLflow.
    """
    with mlflow.start_run(run_name=model_name):
        # Train
        model.fit(X_train, y_train)

        # Predict
        y_pred = model.predict(X_test)

        # Metrics
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred)
        rec = recall_score(y_test, y_pred)

        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision", prec)
        mlflow.log_metric("recall", rec)

        # Log model as real MLflow model
        mlflow.sklearn.log_model(model, model_name)

        print(f"\n=== {model_name} RESULTS ===")
        print(f"Accuracy: {acc:.4f}")
        print(f"Precision: {prec:.4f}")
        print(f"Recall: {rec:.4f}")

models = {
    "DecisionTree": DecisionTreeClassifier(),
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "RandomForest": RandomForestClassifier(n_estimators=100)
}

for model_name, model in models.items():
    evaluate_and_log(model_name, model, X_train, y_train, X_test, y_test)

print("\nAll models trained and logged to MLflow.\n")
